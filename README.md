\# ğŸ¤– My ChatGPT Clone (Streaming + IA Local)



Clon funcional de ChatGPT construido con arquitectura full-stack moderna, implementando streaming en tiempo real mediante Server-Sent Events (SSE) e integraciÃ³n con modelo de IA local vÃ­a Ollama.



Proyecto desarrollado como parte de mi portafolio tÃ©cnico para demostrar habilidades en arquitectura cliente-servidor, streaming en tiempo real y buenas prÃ¡cticas de desarrollo.



---



\## ğŸ¯ Objetivo del Proyecto



Construir un clon funcional de ChatGPT aplicando:



\- SeparaciÃ³n clara entre frontend y backend

\- Streaming en tiempo real (SSE)

\- IntegraciÃ³n con modelo de IA local

\- Control de versiones profesional con Git

\- DocumentaciÃ³n clara y reproducible



---



\## ğŸš€ TecnologÃ­as Utilizadas



\### ğŸ–¥ Frontend

\- React (Vite)

\- Server-Sent Events (SSE)

\- Manejo de estado con hooks

\- UI estilo ChatGPT

\- CSS modular



\### âš™ Backend

\- Node.js

\- Express

\- Streaming HTTP (SSE)

\- IntegraciÃ³n con Ollama (modelo Llama 3 local)

\- Arquitectura REST



\### ğŸ§  IA

\- Ollama

\- Llama3 (modelo local gratuito)



---



\## ğŸ§± Arquitectura



El proyecto sigue una arquitectura cliente-servidor:



1\. El usuario escribe un mensaje en el frontend (React).

2\. El frontend envÃ­a el historial al backend vÃ­a POST.

3\. El backend:

&nbsp;  - Procesa el mensaje

&nbsp;  - Llama al modelo local en Ollama

&nbsp;  - Recibe la respuesta en streaming

&nbsp;  - ReenvÃ­a los fragmentos al cliente usando SSE

4\. El frontend actualiza la interfaz progresivamente con los deltas recibidos.



Esto permite una experiencia similar a ChatGPT real.



---



\## ğŸ§  CaracterÃ­sticas Principales



\- Streaming de respuesta en tiempo real

\- IntegraciÃ³n con modelo local (sin costos de API)

\- Manejo de errores

\- SeparaciÃ³n clara de responsabilidades

\- CÃ³digo modular y comentado

\- Buenas prÃ¡cticas con Git (.gitignore, commits estructurados)



---



\## ğŸ“‚ Estructura del Proyecto



my-chatgpt-clone/

â”‚

â”œâ”€â”€ client/ # Frontend React

â”‚ â”œâ”€â”€ src/

â”‚ â””â”€â”€ package.json

â”‚

â”œâ”€â”€ server/ # Backend Express

â”‚ â”œâ”€â”€ server.js

â”‚ â””â”€â”€ package.json

â”‚

â”œâ”€â”€ .gitignore

â””â”€â”€ README.md





---



\## âš™ InstalaciÃ³n y EjecuciÃ³n Local



\### 1ï¸âƒ£ Clonar repositorio



```bash

git clone https://github.com/TU\_USUARIO/my-chatgpt-clone.git

cd my-chatgpt-clone





2\. Instalar dependencias



Backend

cd server

npm install





Frontend

cd ../client

npm install





3\. Instalar Ollama (IA local)



Descargar desde:



ğŸ‘‰ https://ollama.com



Descargar modelo:

ollama pull llama3.2:3b





4\.  Ejecutar Backend



cd server

node server.js





Servidor disponible en: http://localhost:8080





5\. Ejecutar Frontend



cd client

npm run dev



AplicaciÃ³n disponible en: http://localhost:5173





ğŸ“¸ Vista Previa



Interfaz estilo ChatGPT con:



Mensajes diferenciados usuario / asistente



Indicador de "Escribiendo..."



Streaming progresivo de respuesta



ğŸ“š Aprendizajes Clave



Durante este proyecto reforcÃ©:



ImplementaciÃ³n de streaming con SSE



Manejo avanzado de estados en React



IntegraciÃ³n de modelos de IA locales



Arquitectura full-stack desacoplada



Flujo profesional de Git y control de versiones



ğŸ”® Mejoras Futuras



Persistencia de historial en base de datos



AutenticaciÃ³n de usuarios



Soporte multi-modelo (OpenAI / Claude / Local)



Deploy en Vercel + Render



VersiÃ³n SaaS multi-tenant



ğŸ‘©â€ğŸ’» Autora



Angie Gomez



GitHub: https://github.com/angieg2400/my-chatgpt-clone.git



LinkedIn: www.linkedin.com/in/angie-gÃ³mez-benavides-3b5378342



